{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "import matplotlib.pyplot as pyplot\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data, target = load_wine(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data and target examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Data \",data[130],\"\\ntarget \",target[130])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting indexes in order to plot with different colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(target[target==0]))\n",
    "print(len(target[target==1]))\n",
    "print(len(target[target==2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pyplot.plot(data[:, :2][:59], 'bo', data[:, :2][59:59+71], 'go', data[:, :2][59+71:59+71+48], 'ro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data in Train (50%), Validation (20%) and Test (30%) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data_train, Data_test, Target_train, Target_test = train_test_split(data, target, test_size=0.30, random_state=42)\n",
    "Data_train, Data_validation, Target_train, Target_validation = train_test_split(Data_train, Target_train, test_size=0.20, random_state=41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plotting method\n",
    "step_size = 0.02\n",
    "# Create color maps\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "def plot_boundaries(model, data_train, target_train, n_neighbors):\n",
    "    data_0, data_1 = np.meshgrid(np.arange(data_train[:, 0].min() - 1, data_train[:, 0].max() + 1 , step_size),\n",
    "                     np.arange(data_train[:, 1].min()-1, data_train[:, 1].max()+1, step_size))\n",
    "    predictions = model.predict(np.c_[data_0.ravel(), data_1.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    predictions = predictions.reshape(data_0.shape)\n",
    "    pyplot.figure()\n",
    "    pyplot.pcolormesh(data_0, data_1, predictions, cmap=cmap_light)\n",
    "\n",
    "    # Plot also the training points\n",
    "    pyplot.scatter(data_train[:, 0], data_train[:, 1], c=target_train, cmap=cmap_bold)\n",
    "    pyplot.xlim(data_0.min(), data_0.max())\n",
    "    pyplot.ylim(data_1.min(), data_1.max())\n",
    "    pyplot.title(\"3-Class classification (k = %i)\"\n",
    "              % (n_neighbors))\n",
    "\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting values for k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K = [1, 3, 5, 7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting decision boundaries and predicting on validation split with different values for k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "\n",
    "model = KNeighborsClassifier(1, weights='uniform')\n",
    "model.fit(Data_train[:, :2], Target_train)\n",
    "\n",
    "for k in K:\n",
    "    model.set_params(n_neighbors=k)\n",
    "    \n",
    "    #Plotting boundaries\n",
    "    plot_boundaries(model, Data_train, Target_train, k)\n",
    "    \n",
    "    #Predicting on validation split\n",
    "    predictions_valid = model.predict(Data_validation[:, :2])\n",
    "    score_valid = (predictions_valid[predictions_valid==Target_validation].sum())/len(Target_validation)\n",
    "    print(\"Result for validation split with k= \",k,\" \",score_valid,\"%\")\n",
    "    accuracies.append(score_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting accuracies for each value of k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pyplot.plot(K, accuracies, 'bo')\n",
    "pyplot.title('Accuracy for each k')\n",
    "pyplot.xlabel('k')\n",
    "pyplot.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting best value for k, based on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_k = np.argmax(accuracies)\n",
    "best_k = K[best_k]\n",
    "print(\"Best value is \",best_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Setting k to its best value\n",
    "model.set_params(n_neighbors=best_k)\n",
    "\n",
    "test_predictions = model.predict(Data_test[:, :2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score_test = (test_predictions[test_predictions==Target_test].sum())/len(Target_test)\n",
    "print(\"Result for test set with k= \",best_k,\" \",score_test,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_boundaries_svm(model, data_train, target_train, c, l=-1000):\n",
    "    data_0, data_1 = np.meshgrid(np.arange(data_train[:, 0].min() - 1, data_train[:, 0].max() + 1 , step_size),\n",
    "                     np.arange(data_train[:, 1].min()-1, data_train[:, 1].max()+1, step_size))\n",
    "    predictions = model.predict(np.c_[data_0.ravel(), data_1.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    predictions = predictions.reshape(data_0.shape)\n",
    "    pyplot.figure()\n",
    "    pyplot.pcolormesh(data_0, data_1, predictions, cmap=cmap_light)\n",
    "\n",
    "    # Plot also the training points\n",
    "    pyplot.scatter(data_train[:, 0], data_train[:, 1], c=target_train, cmap=cmap_bold)\n",
    "    pyplot.xlim(data_0.min(), data_0.max())\n",
    "    pyplot.ylim(data_1.min(), data_1.max())\n",
    "    if l == -1000:\n",
    "        pyplot.title(\"3-Class classification (c = %i)\"\n",
    "              % (c))\n",
    "    else:\n",
    "        pyplot.title(\"3-Class classification (c = %i, l = %f)\"\n",
    "              % (c, l))\n",
    "\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting possible values for C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C = [0.001, 0.01, 0.1, 1, 10, 100, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "for c in C:    \n",
    "    modelSVM = svm.LinearSVC(C=c)\n",
    "    modelSVM.fit(Data_train[:,:2], Target_train)\n",
    "    \n",
    "    #Plotting boundaries\n",
    "    plot_boundaries_svm(modelSVM, Data_train, Target_train, c)\n",
    "    \n",
    "    #Predicting on validation split\n",
    "    predictions_valid = modelSVM.predict(Data_validation[:, :2])\n",
    "    score_valid = (predictions_valid[predictions_valid==Target_validation].sum())/len(Target_validation)\n",
    "    print(\"Result for validation split with c= \",c,\" \",score_valid,\"%\")\n",
    "    accuracies.append(score_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pyplot.plot(C, accuracies, 'bo')\n",
    "pyplot.title('Accuracy for each c')\n",
    "pyplot.xlabel('c')\n",
    "pyplot.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting best value for c, based on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_c = np.argmax(accuracies)\n",
    "best_c = C[best_c]\n",
    "print(\"Best value is \",best_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Evaluating on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Setting c to its best value\n",
    "modelSVM = svm.LinearSVC(C=best_c)\n",
    "modelSVM.fit(Data_train[:,:2], Target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_predictions = modelSVM.predict(Data_test[:, :2])\n",
    "score_test = (test_predictions[test_predictions==Target_test].sum())/len(Target_test)\n",
    "print(\"Result for test set with c = \",best_c,\" \",score_test,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBF Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "for c in C:    \n",
    "    modelSVM = svm.SVC(C=c, kernel='rbf')\n",
    "    modelSVM.fit(Data_train[:,:2], Target_train)\n",
    "    \n",
    "    #Plotting boundaries\n",
    "    plot_boundaries_svm(modelSVM, Data_train, Target_train, c)\n",
    "    \n",
    "    #Predicting on validation split\n",
    "    predictions_valid = modelSVM.predict(Data_validation[:, :2])\n",
    "    score_valid = (predictions_valid[predictions_valid==Target_validation].sum())/len(Target_validation)\n",
    "    print(\"Result for validation split with c= \",c,\" \",score_valid,\"%\")\n",
    "    accuracies.append(score_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_c = np.argmax(accuracies)\n",
    "best_c = C[best_c]\n",
    "print(\"Best value is \",best_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_predictions = modelSVM.predict(Data_test[:, :2])\n",
    "score_test = (test_predictions[test_predictions==Target_test].sum())/len(Target_test)\n",
    "print(\"Result for test set with c = \",best_c,\" \",score_test,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting values for gamma (l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L = [0.001, 0.01, 0.1, 1, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "for c in C:\n",
    "    accuracies.append([])\n",
    "    for l in L:\n",
    "        modelSVM = svm.SVC(C=c, kernel='rbf', gamma=l)\n",
    "        modelSVM.fit(Data_train[:,:2], Target_train)\n",
    "    \n",
    "        #Predicting on validation split\n",
    "        predictions_valid = modelSVM.predict(Data_validation[:, :2])\n",
    "        score_valid = (predictions_valid[predictions_valid==Target_validation].sum())/len(Target_validation)\n",
    "        print(\"Result for validation split with c= \",c,\" and l= \",l,\" \",score_valid,\"%\")\n",
    "        accuracies[len(accuracies)-1].append(score_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searching for best values of c and l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_c = 0\n",
    "best_l = 0\n",
    "for c in range(len(C)):\n",
    "    l = np.argmax(accuracies[c])\n",
    "    if accuracies[c][l] > accuracies[best_c][best_l]:\n",
    "        best_c = c\n",
    "        best_l = l\n",
    "best_c = C[best_c]\n",
    "best_l = L[best_l]\n",
    "print(\"Best value for c = \",best_c)\n",
    "print(\"Best value for l = \",best_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modelSVM = svm.SVC(C=best_c, kernel='rbf', gamma=best_l)\n",
    "modelSVM.fit(Data_train[:,:2], Target_train)\n",
    "    \n",
    "test_predictions = modelSVM.predict(Data_test[:, :2])\n",
    "score_test = (test_predictions[test_predictions==Target_test].sum())/len(Target_test)\n",
    "print(\"Result for test set with c = \",best_c,\" and l = \",best_l,\" \",score_test,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Plotting boundaries\n",
    "plot_boundaries_svm(modelSVM, Data_train, Target_train, best_c, best_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K_Fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging train and validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Data_train = np.concatenate((Data_train, Data_validation))\n",
    "Target_train = np.concatenate((Target_train, Target_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing number of samples to take in each k-fold validation iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_samples = int(20/100*len(Target_train))\n",
    "print(n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "for c in C:\n",
    "    accuracies.append([])\n",
    "    for l in L:\n",
    "        score_valids = []\n",
    "        for i in range(5):\n",
    "            \n",
    "            #Extracting validation samples\n",
    "            starting_index = i*n_samples\n",
    "            Data_validation = Data_train[starting_index:starting_index+n_samples]\n",
    "            Target_validation = Target_train[starting_index:starting_index+n_samples]\n",
    "            \n",
    "            #Extracting remaining samples\n",
    "            Data_train_tmp = np.concatenate((Data_train[:starting_index], Data_train[starting_index+n_samples:]))\n",
    "            Target_train_tmp = np.concatenate((Target_train[:starting_index], Target_train[starting_index+n_samples:]))\n",
    "            \n",
    "            #Fitting train set\n",
    "            modelSVM = svm.SVC(C=c, kernel='rbf', gamma=l)\n",
    "            modelSVM.fit(Data_train_tmp[:,:2], Target_train_tmp)\n",
    "    \n",
    "            #Predicting on validation split\n",
    "            predictions_valid = modelSVM.predict(Data_validation[:, :2])\n",
    "            score_valids.append((predictions_valid[predictions_valid==Target_validation].sum())/len(Target_validation))\n",
    "            \n",
    "        #Computing mean of result for current values of hyperparameters\n",
    "        score_valid = (sum(score_valids))/5\n",
    "        print(\"Result for validation split with c= \",c,\" and l= \",l,\" \",score_valid,\"%\")\n",
    "        accuracies[len(accuracies)-1].append(score_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searching for best values of c and l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_c = 0\n",
    "best_l = 0\n",
    "for c in range(len(C)):\n",
    "    l = np.argmax(accuracies[c])\n",
    "    if accuracies[c][l] > accuracies[best_c][best_l]:\n",
    "        best_c = c\n",
    "        best_l = l\n",
    "best_c = C[best_c]\n",
    "best_l = L[best_l]\n",
    "print(\"Best value for c = \",best_c)\n",
    "print(\"Best value for l = \",best_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modelSVM = svm.SVC(C=best_c, kernel='rbf', gamma=best_l)\n",
    "modelSVM.fit(Data_train[:,:2], Target_train)\n",
    "    \n",
    "test_predictions = modelSVM.predict(Data_test[:, :2])\n",
    "score_test = (test_predictions[test_predictions==Target_test].sum())/len(Target_test)\n",
    "print(\"Result for test set with c = \",best_c,\" and l = \",best_l,\" \",score_test,\"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [cntk-py35]",
   "language": "python",
   "name": "Python [cntk-py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
